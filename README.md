
# ğŸ Snake Game Reinforcement Learning â€” Q-Learning vs SARSA

This project implements the classic Snake game using **Reinforcement Learning (RL)** algorithms â€” **Q-Learning** and **SARSA** â€” and compares their performance across 500 training episodes.

Agents learn to play Snake autonomously through reward-based interaction, and their behavior is visualized with real-time video and performance graphs.

## ğŸ“Œ Project Highlights

- âœ… Implemented with **Pygame** and **Python**
- ğŸ§  Two RL algorithms: **Q-Learning** (off-policy) and **SARSA** (on-policy)
- ğŸ“Š Performance comparison through average scores, best scores, and stability
- ğŸ¥ Side-by-side video generation of trained agents
- ğŸ“ˆ Graphical visualization of learning curves


## ğŸš€ Quick Start

### 1. Clone the Repository
```bash
git clone https://github.com/snehapadgaonkar/SnakeRL.git
cd SnakeRL
```

### 2. Install Dependencies
```bash
pip install pygame numpy imageio matplotlib opencv-python
```

### 3. Run the Notebook
Open `snake_rl.ipynb` in Jupyter or Colab and run all cells to train and evaluate both agents.

## ğŸ¤– Algorithms Overview

| Q-Learning                         | SARSA                              |
|-----------------------------------|------------------------------------|
| Off-policy                        | On-policy                          |
| Uses `max(Q(s', a'))` for update | Uses `Q(s', a')` (actual action)   |
| Faster learning, less stable      | Slower, but more stable behavior   |

> ğŸ” Both agents were trained for **500 games** each.

## ğŸ“Š Results Summary

| Metric                  | Q-Learning | SARSA     |
|-------------------------|------------|-----------|
| Best Score              | âœ… Higher  | âŒ Lower  |
| Average Score           | âœ… Higher  | âŒ Lower  |
| Cumulative Score        | âŒ Lower   | âœ… Higher |
| Training Time           | âœ… Lower   | âŒ Higher |
| Stability               | âŒ Less    | âœ… More   |

## ğŸ¥ Sample Output

The notebook generates a **side-by-side video** of both agents playing after training and plots a **score graph** over time.

## ğŸ“ References

- Sutton & Barto: *Reinforcement Learning â€” An Introduction*
- OpenAI Gym (for RL benchmarking environments)
- Python Pygame documentation


## ğŸ“Œ Future Work

- Implement **Deep Q-Learning (DQN)** using neural networks
- Add state visualization or heatmaps
- Save and load trained Q-tables
